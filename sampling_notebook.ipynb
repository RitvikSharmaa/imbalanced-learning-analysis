{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM3JJazognUEt6EWLvSEMi6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dPcbdHop1lFv","executionInfo":{"status":"ok","timestamp":1768970169050,"user_tz":-330,"elapsed":12603,"user":{"displayName":"Ritvik Sharma","userId":"05378073420943312079"}},"outputId":"d576e8f7-35dc-4c22-9579-3274fe82f486"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Accuracy Table (%):\n","              RandomUnder  RandomOver  SMOTE  NearMiss  SMOTEENN\n","Logistic            33.33       91.70  91.48    100.00     93.64\n","DecisionTree        50.00       98.69  96.29     83.33     97.50\n","RandomForest        33.33      100.00  99.34     83.33     99.32\n","KNN                 16.67       96.51  94.54     83.33     97.73\n","NaiveBayes          66.67       77.51  73.36     83.33     71.14\n","\n","Best Sampling Technique per Model:\n","Logistic          NearMiss\n","DecisionTree    RandomOver\n","RandomForest    RandomOver\n","KNN               SMOTEENN\n","NaiveBayes        NearMiss\n","dtype: object\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import GaussianNB\n","\n","from imblearn.under_sampling import RandomUnderSampler, NearMiss\n","from imblearn.over_sampling import RandomOverSampler, SMOTE\n","from imblearn.combine import SMOTEENN\n","\n","# ----------------------------\n","# 1. Load Dataset\n","# ----------------------------\n","url = \"https://raw.githubusercontent.com/AnjulaMehto/Sampling_Assignment/main/Creditcard_data.csv\"\n","data = pd.read_csv(url)\n","\n","X = data.drop(\"Class\", axis=1)\n","y = data[\"Class\"]\n","\n","# Standardize\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# ----------------------------\n","# 2. Sampling Techniques\n","# ----------------------------\n","samplers = {\n","    \"RandomUnder\": RandomUnderSampler(),\n","    \"RandomOver\": RandomOverSampler(),\n","    \"SMOTE\": SMOTE(),\n","    \"NearMiss\": NearMiss(),\n","    \"SMOTEENN\": SMOTEENN()\n","}\n","\n","# ----------------------------\n","# 3. Models\n","# ----------------------------\n","models = {\n","    \"Logistic\": LogisticRegression(max_iter=1000),\n","    \"DecisionTree\": DecisionTreeClassifier(),\n","    \"RandomForest\": RandomForestClassifier(),\n","    \"KNN\": KNeighborsClassifier(),\n","    \"NaiveBayes\": GaussianNB()\n","}\n","\n","# ----------------------------\n","# 4. Run experiments\n","# ----------------------------\n","results = pd.DataFrame()\n","\n","for samp_name, sampler in samplers.items():\n","    X_res, y_res = sampler.fit_resample(X, y)\n","\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X_res, y_res, test_size=0.3, random_state=42\n","    )\n","\n","    for model_name, model in models.items():\n","        model.fit(X_train, y_train)\n","        y_pred = model.predict(X_test)\n","        acc = accuracy_score(y_test, y_pred)\n","\n","        results.loc[model_name, samp_name] = round(acc * 100, 2)\n","\n","# ----------------------------\n","# 5. Print results\n","# ----------------------------\n","print(\"\\nAccuracy Table (%):\")\n","print(results)\n","\n","# Best sampling for each model\n","print(\"\\nBest Sampling Technique per Model:\")\n","print(results.idxmax(axis=1))\n"]},{"cell_type":"code","source":[],"metadata":{"id":"bvNORLis1l65"},"execution_count":null,"outputs":[]}]}